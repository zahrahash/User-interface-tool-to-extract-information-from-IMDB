{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from selenium import webdriver\n",
    "from PIL import ImageTk, Image\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9737</th>\n",
       "      <td>5476944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>5914996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>6397426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>8391976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>101726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9742 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       imdbId\n",
       "0      114709\n",
       "1      113497\n",
       "2      113228\n",
       "3      114885\n",
       "4      113041\n",
       "...       ...\n",
       "9737  5476944\n",
       "9738  5914996\n",
       "9739  6397426\n",
       "9740  8391976\n",
       "9741   101726\n",
       "\n",
       "[9742 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLs = pd.read_csv('URLs.csv')\n",
    "URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform web scraping\n",
    "def scrape_data():\n",
    "    result_text.delete('1.0', tk.END)\n",
    "    # List to store the scraped data\n",
    "    titles = []\n",
    "    release_years = []\n",
    "    age_classifications = []\n",
    "    runtimes = []\n",
    "    rates = []\n",
    "    genres = []\n",
    "    movie_stories = []\n",
    "    directors = []\n",
    "    writerss = []\n",
    "    starss = []\n",
    "    \n",
    "    # Get the code from the text box\n",
    "    user_input = url_entry.get()\n",
    "\n",
    "    # Check if IMDb code is empty\n",
    "    if not user_input:\n",
    "        result_text.tag_configure(\"notification\", foreground=\"red\", font=(\"Arial\", 12, \"bold\"))\n",
    "        result_text.insert(tk.END, \"Please enter an IMDb code!\", \"notification\")\n",
    "        url_entry.delete(0, tk.END)\n",
    "        return\n",
    "    \n",
    "    # Create the URL\n",
    "    url = \"https://www.imdb.com/title/tt0\"\n",
    "    final_URL = url + user_input + \"/\"\n",
    "    # Create a web driver\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    \n",
    "    try:\n",
    "        # Load the URL in the Chrome webdriver\n",
    "        driver.get(final_URL)\n",
    "        content = driver.page_source\n",
    "        soup = bs(content, 'html.parser')\n",
    "\n",
    "        # Check if the page exists\n",
    "        error_message = soup.find('div', class_='error_code')\n",
    "        if error_message is not None:\n",
    "            result_text.tag_configure(\"notification\", foreground=\"red\", font=(\"Arial\", 12, \"bold\"))\n",
    "            result_text.insert(tk.END, \"The IMDb code is wrong or the page does not exist.\", \"notification\")\n",
    "            url_entry.delete(0, tk.END)\n",
    "            return\n",
    "        \n",
    "        # Scrape the data (similar to your existing code)\n",
    "        try:\n",
    "            title = soup.find('h1').text\n",
    "            titles.append(title)\n",
    "            result_text.insert(tk.END, f\"Title: {title}\\n\")\n",
    "        except:\n",
    "            titles.append(None)\n",
    "            result_text.insert(tk.END, \"Title: Not available\\n\")\n",
    "            \n",
    "        try:\n",
    "            x = soup.find('ul', class_='ipc-inline-list ipc-inline-list--show-dividers sc-afe43def-4 kdXikI baseAlt')\n",
    "            release_year = x.find_all('a')[0].text\n",
    "            release_years.append(release_year)\n",
    "            result_text.insert(tk.END, f\"Release Year: {release_year}\\n\")\n",
    "        except:\n",
    "            release_years.append(None)\n",
    "            result_text.insert(tk.END, \"Release Year: Not available\\n\")\n",
    "        \n",
    "        try:\n",
    "            age_classification = x.find_all('a')[1].text\n",
    "            age_classifications.append(age_classification)\n",
    "            result_text.insert(tk.END, f\"Age Classification: {age_classification}\\n\")\n",
    "        except:\n",
    "            age_classifications.append(None)\n",
    "            result_text.insert(tk.END, \"Age Classification: Not available\\n\")\n",
    "        \n",
    "        runtime_elem = soup.find('li', {'data-testid': 'title-techspec_runtime'})\n",
    "        if runtime_elem is not None:\n",
    "            runtime = runtime_elem.find('div', {'class': 'ipc-metadata-list-item__content-container'}).text.strip()\n",
    "            runtimes.append(runtime)\n",
    "            result_text.insert(tk.END, f\"Runtime: {runtime}\\n\")\n",
    "        else:\n",
    "            runtimes.append('')\n",
    "            result_text.insert(tk.END, \"Runtime: Not available\\n\")\n",
    "\n",
    "        try:\n",
    "            rate = soup.find('span', class_='sc-bde20123-1 iZlgcd').text\n",
    "            rates.append(rate)\n",
    "            result_text.insert(tk.END, f\"IMDB score: {rate}\\n\")\n",
    "        except:\n",
    "            rates.append(None)\n",
    "            result_text.insert(tk.END, \"IMDB score: Not available\\n\")\n",
    "\n",
    "        try:\n",
    "            genre_tags = soup.find_all('a', class_='ipc-chip ipc-chip--on-baseAlt')\n",
    "            genres_list = [tag.text for tag in genre_tags]\n",
    "            genres.append(', '.join(genres_list))\n",
    "            result_text.insert(tk.END, f\"Genres: {', '.join(genres_list)}\\n\")\n",
    "        except:\n",
    "            genres.append(None)\n",
    "            result_text.insert(tk.END, \"Genres: Not available\\n\")\n",
    "\n",
    "        try:\n",
    "            movie_story = soup.find('span', class_='sc-6a7933c5-0 cUeLJx').text\n",
    "            movie_stories.append(movie_story)\n",
    "            result_text.insert(tk.END, f\"Synopsis: {movie_story}\\n\")\n",
    "        except:\n",
    "            movie_stories.append(None)\n",
    "            result_text.insert(tk.END, \"Synopsis: Not available\\n\")\n",
    "        \n",
    "        credit_items = soup.find_all('li', {'class': 'ipc-metadata-list__item', 'data-testid': 'title-pc-principal-credit'})\n",
    "        director = credit_items[0].find('a').text\n",
    "        directors.append(director)\n",
    "        result_text.insert(tk.END, f\"Director: {director}\\n\")\n",
    "\n",
    "        writers = []\n",
    "        stars = []\n",
    "        for item in credit_items[1:3]:\n",
    "            people = item.find('ul')\n",
    "            x = people.find_all('a')\n",
    "            if 'Writer' in item.text:\n",
    "                writers = [person.text for person in x]\n",
    "            elif 'Stars' in item.text:\n",
    "                stars = [person.text for person in x]\n",
    "\n",
    "        writerss.append(', '.join(writers))\n",
    "        starss.append(', '.join(stars))\n",
    "        result_text.insert(tk.END, f\"Writers: {', '.join(writers)}\\n\")\n",
    "        result_text.insert(tk.END, f\"Stars: {', '.join(stars)}\\n\")\n",
    "\n",
    "        # Prompt the user to save the information\n",
    "        save_prompt = tk.Toplevel(window,bg=\"#858585\")\n",
    "        save_prompt.title(\"Save Information\")\n",
    "        save_label = tk.Label(save_prompt, text=\"Do you want to save the information?\", bg=\"#858585\", font=(\"Arial\", 12), fg=\"white\")\n",
    "        save_label.pack()\n",
    "        \n",
    "        # Lambda function with a condition to handle missing age_classification variable\n",
    "        save_button_yes = tk.Button(save_prompt, text=\"Yes\",bg=\"green\", fg=\"white\", font=(\"Arial\", 10), command=lambda: (save_data(\n",
    "            title if 'title' in locals() else None,\n",
    "            release_year if 'release_year' in locals() else None,\n",
    "            age_classification if 'age_classification' in locals() else None,\n",
    "            runtime if 'runtime' in locals() else None,\n",
    "            rate if 'rate' in locals() else None,\n",
    "            genres_list if 'genres_list' in locals() else None,\n",
    "            movie_story if 'movie_story' in locals() else None,\n",
    "            director if 'director' in locals() else None,\n",
    "            writers if 'writers' in locals() else None,\n",
    "            stars if 'stars' in locals() else None\n",
    "        ),save_prompt.destroy()))\n",
    "        save_button_yes.pack(side=tk.LEFT)\n",
    "        \n",
    "        save_button_no = tk.Button(save_prompt, text=\"No\",bg=\"red\", fg=\"white\", font=(\"Arial\", 10), command=save_prompt.destroy)\n",
    "        save_button_no.pack(side=tk.LEFT,padx=5)\n",
    "        \n",
    "    except Exception as e:\n",
    "        result_text.tag_configure(\"notification\", foreground=\"red\", font=(\"Arial\", 12, \"bold\"))\n",
    "        result_text.insert(tk.END, f\"Error occurred while scraping data: {e}\", \"notification\")\n",
    "        url_entry.delete(0, tk.END)\n",
    "\n",
    "    # Close the web driver\n",
    "    driver.quit()\n",
    "    url_entry.delete(0, tk.END)\n",
    "\n",
    "\n",
    "# Function to extract and save user comments\n",
    "def extract_comments():\n",
    "    titles = []\n",
    "    comments = []\n",
    "    reviews_text.delete('1.0', tk.END)\n",
    "    # Get the code from the text box\n",
    "    user_input = url_entry.get()\n",
    "\n",
    "    # Check if IMDb code is empty\n",
    "    if not user_input:\n",
    "        reviews_text.tag_configure(\"notification\", foreground=\"red\", font=(\"Arial\", 12, \"bold\"))\n",
    "        reviews_text.insert(tk.END, \"Please enter an IMDb code!\", \"notification\")\n",
    "        url_entry.delete(0, tk.END)\n",
    "        return\n",
    "    \n",
    "    # Create the URL\n",
    "    url = \"https://www.imdb.com/title/tt0\"\n",
    "    final_URL = url + user_input + \"/\"\n",
    "    \n",
    "    # Create a web driver\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    \n",
    "    try:\n",
    "        # Load the URL in the Chrome webdriver\n",
    "        driver.get(final_URL)\n",
    "        content = driver.page_source\n",
    "        soup = bs(content, 'html.parser')\n",
    "        \n",
    "        # Check if the page exists\n",
    "        error_message = soup.find('div', class_='error_code')\n",
    "        if error_message is not None:\n",
    "            reviews_text.tag_configure(\"notification\", foreground=\"red\", font=(\"Arial\", 12, \"bold\"))\n",
    "            reviews_text.insert(tk.END, \"The IMDb code is wrong or the page does not exist.\", \"notification\")\n",
    "            url_entry.delete(0, tk.END)\n",
    "            return\n",
    "        \n",
    "        title = soup.find('h1').text\n",
    "        titles.append(title)\n",
    "        reviews_text.insert(tk.END, f\"Title: {title}\\n\\n\")\n",
    "        \n",
    "        # Wait for the user review button to be clickable and click it\n",
    "        user_review_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.LINK_TEXT, 'User reviews')))\n",
    "        user_review_button.click()\n",
    "        \n",
    "        \n",
    "        # Wait for the reviews to load using an explicit wait\n",
    "        while True:\n",
    "            try:\n",
    "                load_more_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.ID, 'load-more-trigger')))\n",
    "                load_more_button.click()\n",
    "                time.sleep(2)  # Wait for new reviews to load\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        # Extract the reviews using BeautifulSoup\n",
    "        content = driver.page_source\n",
    "        soup = bs(content, 'html.parser')\n",
    "        reviews = soup.find_all('div', class_='text show-more__control')\n",
    "        user_reviews = [review.text.strip() for review in reviews]\n",
    "        comments.extend(user_reviews)\n",
    "        \n",
    "        # Display the comments in the result text box\n",
    "        reviews_text.insert(tk.END, \"User Reviews:\\n\")\n",
    "        for i, review in enumerate(user_reviews):\n",
    "            reviews_text.insert(tk.END, f\"\\nReview {i+1}:\\n{review}\\n\")\n",
    "        \n",
    "        # Prompt the user to save the comments\n",
    "        save_prompt = tk.Toplevel(window,bg=\"#858585\")\n",
    "        save_prompt.title(\"Save Comments\")\n",
    "        \n",
    "        save_label = tk.Label(save_prompt, text=\"Do you want to save the comments?\", bg=\"#858585\", font=(\"Arial\", 12), fg=\"white\")\n",
    "        save_label.pack()\n",
    "        \n",
    "        save_button_yes = tk.Button(save_prompt, text=\"Yes\",bg=\"green\", fg=\"white\",font=(\"Arial\", 10), command=lambda: (save_comments(title, comments),save_prompt.destroy()))\n",
    "        save_button_yes.pack(side=tk.LEFT)\n",
    "        \n",
    "        save_button_no = tk.Button(save_prompt, text=\"No\",bg=\"red\", fg=\"white\",font=(\"Arial\", 10), command=save_prompt.destroy)\n",
    "        save_button_no.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "    except Exception as e:\n",
    "        reviews_text.tag_configure(\"notification\", foreground=\"red\", font=(\"Arial\", 12, \"bold\"))\n",
    "        reviews_text.insert(tk.END, f\"Error occurred while scraping data: {e}\", \"notification\")\n",
    "        url_entry.delete(0, tk.END)\n",
    "\n",
    "    # Close the web driver\n",
    "    driver.quit()\n",
    "    url_entry.delete(0, tk.END)\n",
    "\n",
    "\n",
    "# Function to save the data to a CSV file\n",
    "def save_data(title, release_year, age_classification, runtime, rate, genres_list, movie_story, director, writers, stars):\n",
    "    # Assign default values for missing data\n",
    "    if release_year is None:\n",
    "        release_year = \"\"\n",
    "    if age_classification is None:\n",
    "        age_classification = \"\"\n",
    "    if runtime is None:\n",
    "        runtime = \"\"\n",
    "    if rate is None:\n",
    "        rate = \"\"\n",
    "    if genres_list is None:\n",
    "        genres_list = []\n",
    "    if movie_story is None:\n",
    "        movie_story = \"\"\n",
    "    if director is None:\n",
    "        director = \"\"\n",
    "    if writers is None:\n",
    "        writers = []\n",
    "    if stars is None:\n",
    "        stars = []\n",
    "\n",
    "    # Create a dictionary with the data\n",
    "    data = {\n",
    "        'Title': [title],\n",
    "        'Production Year': [release_year],\n",
    "        'Age Classification': [age_classification],\n",
    "        'Runtime': [runtime],\n",
    "        'IMDB Score': [rate],\n",
    "        'Genres': [', '.join(genres_list)],\n",
    "        'Synopsis': [movie_story],\n",
    "        'Director': [director],\n",
    "        'Writers': [', '.join(writers)],\n",
    "        'Stars': [', '.join(stars)]\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Prompt the user to select a file path using a file dialog\n",
    "    save_file_path = filedialog.asksaveasfilename(defaultextension='.csv')\n",
    "    \n",
    "    # Check if the file path exists\n",
    "    if os.path.exists(save_file_path):\n",
    "        # Load the existing data from the file into a DataFrame\n",
    "        existing_df = pd.read_csv(save_file_path)\n",
    "\n",
    "        # Append the new data to the existing DataFrame\n",
    "        updated_df = pd.concat([existing_df, df])\n",
    "\n",
    "        # Save the updated DataFrame to the same file\n",
    "        updated_df.to_csv(save_file_path, index=False)\n",
    "    else:\n",
    "        # Save the new data to a new file\n",
    "        df.to_csv(save_file_path, index=False)\n",
    "\n",
    "    # Display the save message in your GUI\n",
    "    result_text.insert(tk.END, f\"\\nData saved successfully to: {save_file_path}\")\n",
    "    result_text.tag_config(\"save_message\", foreground=\"green\")\n",
    "    result_text.tag_add(\"save_message\", \"insert linestart\", \"insert lineend\")\n",
    "    \n",
    "\n",
    "# Function to save the comments to a text file\n",
    "def save_comments(title, comments):\n",
    "    # Create a string with all the comments\n",
    "    comments_str = f\"{title}\\n\\n\" + '\\n\\n'.join(comments)\n",
    "    # Save the comments to a file using file dialog\n",
    "    save_file_path = filedialog.asksaveasfilename(defaultextension='.txt')\n",
    "    with open(save_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(comments_str)\n",
    "    reviews_text.insert(tk.END, f\"\\nComments saved successfully to: {save_file_path}\")\n",
    "    reviews_text.tag_config(\"save_message\", foreground=\"green\")\n",
    "    reviews_text.tag_add(\"save_message\", \"insert linestart\", \"insert lineend\")\n",
    "\n",
    "\n",
    "# Create the Tkinter application window\n",
    "window = tk.Tk()\n",
    "window.title(\"IMDb Scrapper\")\n",
    "\n",
    "# IMDb-like color scheme\n",
    "bg_color = \"#f5f5f5\"  # Light gray\n",
    "text_color = \"#333333\"  # Dark gray\n",
    "title_font = (\"Arial\", 16, \"bold\")\n",
    "button_font = (\"Arial\", 12, \"bold\")\n",
    "\n",
    "# Set the background color\n",
    "window.configure(bg=\"#333333\")\n",
    "\n",
    "# Create the frames\n",
    "top_frame = tk.Frame(window, bg=\"#333333\")\n",
    "top_frame.pack(side=tk.TOP, fill=tk.X, padx=10, pady=10)\n",
    "\n",
    "result_frame = tk.Frame(window, bg=bg_color)\n",
    "result_frame.pack(padx=80, pady=10)\n",
    "\n",
    "reviews_frame = tk.Frame(window, bg=bg_color)\n",
    "reviews_frame.pack(padx=80, pady=10)\n",
    "\n",
    "# Add the IMDb logo\n",
    "imdb_logo = Image.open(\"logo.png\")  \n",
    "imdb_logo = imdb_logo.resize((140, 70)) \n",
    "imdb_logo = ImageTk.PhotoImage(imdb_logo)\n",
    "logo_label = tk.Label(top_frame, image=imdb_logo, bg=\"#333333\")\n",
    "logo_label.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "# Add a label and text entry for the user input\n",
    "input_label = tk.Label(top_frame, text=\"Enter IMDB code:\", font=title_font, fg=text_color, bg=\"#333333\", foreground=\"white\")\n",
    "input_label.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "url_entry = tk.Entry(top_frame, width=30, font=(\"Arial\", 12))\n",
    "url_entry.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "# Add a button to trigger the data scraping\n",
    "scrape_button = tk.Button(top_frame, text=\"Extract Data\", bg=\"#d9b70f\", fg=\"#333333\", font=button_font, command=scrape_data)\n",
    "scrape_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "# Add a button to trigger the comment extraction\n",
    "extract_button = tk.Button(top_frame, text=\"Extract Comments\", bg=\"#d9b70f\", fg=\"#333333\", font=button_font, command=extract_comments)\n",
    "extract_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "result_label = tk.Label(result_frame, text=\"Scraped Data\", font=title_font, fg=text_color, bg=bg_color)\n",
    "result_label.pack()\n",
    "\n",
    "# Add a text box to display the movie information\n",
    "result_text = tk.Text(result_frame, height=10, width=80, bg=\"#858585\", fg=\"White\", font=(\"Arial\", 12))\n",
    "result_text.pack()\n",
    "\n",
    "reviews_label = tk.Label(reviews_frame, text=\"Scraped Reviews\", font=title_font, fg=text_color, bg=bg_color)\n",
    "reviews_label.pack()\n",
    "\n",
    "# Add a text box to display the user reviews\n",
    "reviews_text = tk.Text(reviews_frame, height=10, width=80, bg=\"#858585\", fg=\"White\", font=(\"Arial\", 12))\n",
    "reviews_text.pack()\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
